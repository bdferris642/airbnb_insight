{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "from copy import *\n",
    "\n",
    "def flatten(l):\n",
    "    flat_list = [item for sublist in l for item in sublist]\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bennett/anaconda3/envs/airbnb_p3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (83) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/bennett/anaconda3/envs/airbnb_p3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (67,85,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "#lis_nyc1 = pd.read_csv('airbnb_similarity_insight/data/air-bnb-listings_nyc1.csv', sep = ';')\n",
    "lis_nyc2 = pd.read_csv('airbnb_similarity_insight/data/airbnb-listings_nyc2.csv', sep = ';')\n",
    "reviews = pd.read_csv('airbnb_similarity_insight/data/airbnb-reviews.csv', sep = ';')\n",
    "rate_nyc = pd.read_csv('airbnb_similarity_insight/data/airbnb-ratings_nyc.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19528\n"
     ]
    }
   ],
   "source": [
    "# How many listings do I have total in nyc\n",
    "   \n",
    "unique_room_id_list = list(np.unique(lis_nyc2['ID']))\n",
    "print(len(unique_room_id_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['room_id', 'listing_url', 'scrape_id', 'last_scraped', 'name',\n",
      "       'summary', 'space', 'description', 'experiences_offered',\n",
      "       'neighborhood_overview', 'notes', 'transit', 'access', 'interaction',\n",
      "       'house_rules', 'thumbnail_url', 'medium_url', 'picture_url',\n",
      "       'xl_picture_url', 'host_id', 'host_url', 'host_name', 'host_since',\n",
      "       'host_location', 'host_about', 'host_response_time',\n",
      "       'host_response_rate', 'host_acceptance_rate', 'host_thumbnail_url',\n",
      "       'host_picture_url', 'host_neighbourhood', 'host_listings_count',\n",
      "       'host_total_listings_count', 'host_verifications', 'street',\n",
      "       'neighbourhood', 'neighborhood_clean', 'neighbourhood_group_cleansed',\n",
      "       'city', 'state', 'zipcode', 'market', 'smart_location', 'country_code',\n",
      "       'country', 'latitude', 'longitude', 'property_type', 'room_type',\n",
      "       'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type',\n",
      "       'amenities', 'square_feet', 'room_price', 'weekly_price',\n",
      "       'monthly_price', 'security_deposit', 'cleaning_fee', 'guests_included',\n",
      "       'extra_people', 'minimum_nights', 'maximum_nights', 'calendar_updated',\n",
      "       'has_availability', 'availability_30', 'availability_60',\n",
      "       'availability_90', 'availability_365', 'calendar_last_scraped',\n",
      "       'number_of_reviews', 'first_review', 'date_last_review',\n",
      "       'review_scores_rating', 'review_scores_accuracy',\n",
      "       'review_scores_cleanliness', 'review_scores_checkin',\n",
      "       'review_scores_communication', 'review_scores_location',\n",
      "       'review_scores_value', 'license', 'jurisdiction_names',\n",
      "       'cancellation_policy', 'calculated_host_listings_count',\n",
      "       'reviews_per_month', 'coordinates', 'features'],\n",
      "      dtype='object')\n",
      "Index(['room_id', 'listing_url', 'scrape_id', 'last_scraped', 'name',\n",
      "       'summary', 'space', 'description', 'experiences_offered',\n",
      "       'neighborhood_overview', 'notes', 'transit', 'access', 'interaction',\n",
      "       'house_rules', 'thumbnail_url', 'medium_url', 'picture_url',\n",
      "       'xl_picture_url', 'host_id', 'host_url', 'host_name', 'host_since',\n",
      "       'host_location', 'host_about', 'host_response_time',\n",
      "       'host_response_rate', 'host_acceptance_rate', 'host_thumbnail_url',\n",
      "       'host_picture_url', 'host_neighbourhood', 'host_listings_count',\n",
      "       'host_total_listings_count', 'host_verifications', 'street',\n",
      "       'neighbourhood', 'neighborhood_clean', 'neighbourhood_group_cleansed',\n",
      "       'city', 'state', 'zipcode', 'market', 'smart_location', 'country_code',\n",
      "       'country', 'latitude', 'longitude', 'property_type', 'room_type',\n",
      "       'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type',\n",
      "       'amenities', 'square_feet', 'room_price', 'weekly_price',\n",
      "       'monthly_price', 'security_deposit', 'cleaning_fee', 'guests_included',\n",
      "       'extra_people', 'minimum_nights', 'maximum_nights', 'calendar_updated',\n",
      "       'has_availability', 'availability_30', 'availability_60',\n",
      "       'availability_90', 'availability_365', 'calendar_last_scraped',\n",
      "       'number_of_reviews', 'first_review', 'date_last_review',\n",
      "       'review_scores_rating', 'review_scores_accuracy',\n",
      "       'review_scores_cleanliness', 'review_scores_checkin',\n",
      "       'review_scores_communication', 'review_scores_location',\n",
      "       'review_scores_value', 'license', 'jurisdiction_names',\n",
      "       'cancellation_policy', 'calculated_host_listings_count',\n",
      "       'reviews_per_month', 'coordinates', 'features'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "lis_nyc2_orig = deepcopy(lis_nyc2)\n",
    "reviews_orig = deepcopy(lis_nyc2)\n",
    "\n",
    "\n",
    "l2d = {'id':'room_id', \n",
    "        'geolocation':'coordinates', \n",
    "        'neighbourhood_cleansed': 'neighborhood_clean',\n",
    "       'price':'room_price',\n",
    "       'last_review':'date_last_review'}\n",
    "lis_nyc2 = lis_nyc2.rename(columns=l2d)\n",
    "\n",
    "lis_nyc2 = lis_nyc2.rename(columns={c:c.lower().replace(' ', '_') for c in lis_nyc2.columns})\n",
    "\n",
    "reviews = reviews.rename(columns={c:c.lower().replace(' ', '_') for c in reviews.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a DataFrame of room_id --> host_name, list of reviewers, list of comments\n",
    "# Takes some compute time (~10 minutes)\n",
    "unique_room_id_list = sorted(unique_room_id_list)\n",
    "hosts_for_room = {room_id: list(lis_nyc2[lis_nyc2.room_id == room_id].host_name) for room_id in unique_room_id_list}\n",
    "reviewers_for_room = {room_id: list(reviews[reviews.listing_id == room_id].reviewer_id) for room_id in unique_room_id_list}\n",
    "comments_for_room = {room_id: list(reviews[reviews.listing_id == room_id].comments) for room_id in unique_room_id_list}\n",
    "room_db = pd.DataFrame({'room_id':unique_room_id_list,\n",
    "                        'host_name':[hosts_for_room[k] for k in unique_room_id_list],\n",
    "                       'user_id':[reviewers_for_room[k] for k in unique_room_id_list],\n",
    "                       'comments': [comments_for_room[k] for k in unique_room_id_list]})\n",
    "\n",
    "import pickle\n",
    "with open('airbnb_similarity_insight/pickles/room_db_nyc.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(room_db, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e806e984bc8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"airbnb_similarity_insight/pickles/room_db_nyc.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mobject_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "file = open(\"airbnb_similarity_insight/pickles/room_db_nyc.pkl\",'rb')\n",
    "object_file = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try some topic modeling\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/bennett/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization: Split the text into sentences and the sentences into words. \n",
    "# Lowercase the words and remove punctuation.\n",
    "\n",
    "# Words that have fewer than 3 characters are removed.\n",
    "\n",
    "# Words are lemmatized — words in third person are changed to first person \n",
    "# and verbs in past and future tenses are changed into present.\n",
    "\n",
    "# Words are stemmed — words are reduced to their root form.\n",
    "\n",
    "# All stopwords are removed.\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19528, 4), (325682, 5))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_doc_comments = []\n",
    "hns = []\n",
    "indices = []\n",
    "rids = []\n",
    "uids = []\n",
    "c_and_i = list(zip(list(room_db.comments), \n",
    "                   list(room_db.host_name),\n",
    "                   list(room_db.index), \n",
    "                   list(room_db.room_id),\n",
    "                   list(room_db.user_id)))\n",
    "for i, (cs, hn, ind, rid, uid) in enumerate(c_and_i):\n",
    "    flat_doc_comments.extend(cs)\n",
    "    hns.extend([hn]*len(cs))\n",
    "    indices.extend([ind]*len(cs))\n",
    "    rids.extend([rid]*len(cs))\n",
    "    uids.extend([uid]*len(cs))\n",
    "\n",
    "flat_room_db = pd.DataFrame({'listing_id':rids, 'host_name': hns, 'user_id':uids,\n",
    "                            'comments':flat_doc_comments, 'indices':indices})\n",
    "\n",
    "room_db.shape, flat_room_db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unforgettable trip to NYC. Fantastic city with crazy people an much to see.\n",
      "original document: \n",
      "['An', 'unforgettable', 'trip', 'to', 'NYC.', 'Fantastic', 'city', 'with', 'crazy', 'people', 'an', 'much', 'to', 'see.']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['unforgett', 'trip', 'fantast', 'citi', 'crazi', 'peopl']\n"
     ]
    }
   ],
   "source": [
    "#data_text = room_db[['comments']]\n",
    "#data_text['index'] = data_text.index\n",
    "#bumpy_documents = data_text\n",
    "#doc_sample = bumpy_documents[bumpy_documents['index'] == 4310].values[0][0]\n",
    "\n",
    "doc_sample = flat_room_db.comments[122]\n",
    "print(doc_sample)\n",
    "\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "detect(\"War doesn't show who's right, just who's left.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bennett/anaconda3/envs/airbnb_p3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-64272067b658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_room_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mflat_room_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_room_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HOST_NAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/airbnb_p3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_with_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airbnb_p3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[0;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[1;32m   3346\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3347\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3348\u001b[0;31m                     \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3349\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3350\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airbnb_p3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   3303\u001b[0m         \"\"\"The object has called back to us saying maybe it has changed.\n\u001b[1;32m   3304\u001b[0m         \"\"\"\n\u001b[0;32m-> 3305\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airbnb_p3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mblk_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m                 \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 \u001b[0munfit_mgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/airbnb_p3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, locs, values)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \"\"\"\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "flat_room_db.comments = flat_room_db.comments.fillna('')\n",
    "for ic, c in enumerate(flat_room_db.comments):\n",
    "    name = flat_room_db.host_name[ic][0]\n",
    "    if name is not np.nan:\n",
    "        flat_room_db.comments[ic]=flat_room_db.comments[ic].replace(name, 'HOST_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Stephanie's offered all the most important thi...\n",
       "1                        awesome couldn't have been better.\n",
       "2         Nous avons passé un agréable séjour chez Stéph...\n",
       "3         We stayed at the 111th Street apartment with S...\n",
       "4         Very conveniently located just North of Centra...\n",
       "                                ...                        \n",
       "325677                  Great stay, great place, great host\n",
       "325678    Great experience! Apartment was clean and tidy...\n",
       "325679    margarita is the perfect host. we very much en...\n",
       "325680    HOST_NAME is a great person, the place below t...\n",
       "325681    HOST_NAME was a great host! The linens were cl...\n",
       "Length: 325682, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = flat_room_db[['host_name', 'comments']]\n",
    "#df['d'] = df.apply(lambda x: some_func(a = x['a'], b = x['b'], c = x['c']), axis=1)\n",
    "def clean_name_df(x):\n",
    "    if type(x['host_name'][0]) is str:\n",
    "        return x['comments'].replace(x['host_name'][0], 'HOST_NAME')\n",
    "    else:\n",
    "        return x['comments']\n",
    "test.apply(lambda x: clean_name_df(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flatt_room_db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5316a338ebfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'No Language'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mflat_room_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatt_room_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mflat_room_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_room_db\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflat_room_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flatt_room_db' is not defined"
     ]
    }
   ],
   "source": [
    "# ONLY LOOKS AT REVIEWS WITH 3+ CHARACTERS\n",
    "# ONLY LOOK AT REVIEWS IN ENGLISH\n",
    "\n",
    "def clean_name_df(x):\n",
    "    if type(x['host_name'][0]) is str:\n",
    "        return x['comments'].replace(x['host_name'][0], 'HOST_NAME')\n",
    "    else:\n",
    "        return x['comments']\n",
    "flat_room_db['comments'] = flat_room_db.apply(lambda x: clean_name_df(x), axis=1)\n",
    "\n",
    "flat_room_db = flat_room_db[flat_room_db.comments.apply(lambda x: len(x) >= 3)]\n",
    "\n",
    "def clean_detect(x):\n",
    "    try:\n",
    "        return detect(x)\n",
    "    except:\n",
    "        return 'No Language'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_room_db = flat_room_db[flat_room_db.comments.apply(lambda x: clean_detect(x) =='en')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_room_db.comments.apply(lambda x: x[:34] != 'The host canceled this reservation')[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Stephanie's offered all the most important thi...\n",
      "1                        awesome couldn't have been better.\n",
      "3         We stayed at the 111th Street apartment with S...\n",
      "4         Very conveniently located just North of Centra...\n",
      "5         We had a great stay with Stephanie and her fam...\n",
      "                                ...                        \n",
      "325677                  Great stay, great place, great host\n",
      "325678    Great experience! Apartment was clean and tidy...\n",
      "325679    margarita is the perfect host. we very much en...\n",
      "325680    HOST_NAME is a great person, the place below t...\n",
      "325681    HOST_NAME was a great host! The linens were cl...\n",
      "Name: comments, Length: 280476, dtype: object\n",
      "0         Stephanie's offered all the most important thi...\n",
      "1                        awesome couldn't have been better.\n",
      "3         We stayed at the 111th Street apartment with S...\n",
      "4         Very conveniently located just North of Centra...\n",
      "5         We had a great stay with Stephanie and her fam...\n",
      "                                ...                        \n",
      "325677                  Great stay, great place, great host\n",
      "325678    Great experience! Apartment was clean and tidy...\n",
      "325679    margarita is the perfect host. we very much en...\n",
      "325680    HOST_NAME is a great person, the place below t...\n",
      "325681    HOST_NAME was a great host! The linens were cl...\n",
      "Name: comments, Length: 280476, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(flat_room_db.comments)\n",
    "# Remove comments with automated message\n",
    "\n",
    "flat_room_db = flat_room_db[flat_room_db.comments.apply(lambda x: x[:34] != 'The host canceled this reservation')]\n",
    "             \n",
    "print(flat_room_db.comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('airbnb_similarity_insight/pickles/flat_room_db_nyc_clean.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(flat_room_db, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280476\n"
     ]
    }
   ],
   "source": [
    "print(len(flat_room_db.comments))\n",
    "processed_comments = flat_room_db['comments'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 access\n",
      "1 away\n",
      "2 blanket\n",
      "3 clean\n",
      "4 comfort\n",
      "5 easi\n",
      "6 feel\n",
      "7 find\n",
      "8 fresh\n",
      "9 futur\n",
      "10 generous\n",
      "11 home\n",
      "12 import\n",
      "13 invit\n",
      "14 manhattan\n",
      "15 offer\n",
      "16 open\n",
      "17 quiet\n",
      "18 room\n",
      "19 stephani\n",
      "20 thing\n",
      "21 towel\n",
      "22 travel\n",
      "23 warm\n",
      "24 welcom\n",
      "25 awesom\n",
      "26 better\n",
      "27 couldn\n",
      "28 abl\n",
      "29 advis\n",
      "30 altern\n",
      "31 apart\n",
      "32 card\n",
      "33 ensur\n",
      "34 famili\n",
      "35 furthest\n",
      "36 hotel\n",
      "37 long\n",
      "38 matter\n",
      "39 overpric\n",
      "40 place\n",
      "41 recommend\n",
      "42 stay\n",
      "43 street\n",
      "44 time\n",
      "45 tourist\n",
      "46 transport\n",
      "47 unlimit\n",
      "48 uptown\n",
      "49 want\n",
      "50 york\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set.\n",
    "dictionary = gensim.corpora.Dictionary(processed_comments)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 40 (\"place\") appears 1 time.\n",
      "Word 41 (\"recommend\") appears 1 time.\n",
      "Word 65 (\"locat\") appears 1 time.\n",
      "Word 140 (\"perfect\") appears 1 time.\n",
      "Word 202 (\"definit\") appears 1 time.\n",
      "Word 208 (\"love\") appears 1 time.\n",
      "Word 1188 (\"vibe\") appears 1 time.\n",
      "Word 1251 (\"cool\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# Filter out tokens that appear in\n",
    "#less than no_below documents (absolute number) or\n",
    "#more than no_above documents (fraction of total corpus size, not absolute number).\n",
    "#after the above two steps, keep only the first 100000 most frequent tokens.\n",
    "\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=100000)\n",
    "\n",
    "#Gensim doc2bow\n",
    "#For each document we create a dictionary reporting how many\n",
    "#words and how many times those words appear. Save this to ‘bow_corpus’, then check our selected document earlier.\n",
    "bow_corpus = [dictionary.doc2bow(comment) for comment in processed_comments]\n",
    "bow_corpus[4310]\n",
    "\n",
    "# Preview Bag Of Words for our sample preprocessed document.\n",
    "bow_doc_4310 = bow_corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "                                                bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.12471894765745287),\n",
      " (1, 0.10890457556812892),\n",
      " (2, 0.23639534226884684),\n",
      " (3, 0.04648951036054526),\n",
      " (4, 0.13275091292456642),\n",
      " (5, 0.07982773410548202),\n",
      " (6, 0.10822668850791249),\n",
      " (7, 0.2416419288644195),\n",
      " (8, 0.19115722972215154),\n",
      " (9, 0.1798599738225504),\n",
      " (10, 0.21316894590729127),\n",
      " (11, 0.3009188482047445),\n",
      " (12, 0.19454932992954152),\n",
      " (13, 0.22285834989627018),\n",
      " (14, 0.11837266494933073),\n",
      " (15, 0.158173881354976),\n",
      " (16, 0.1663581869207859),\n",
      " (17, 0.10037984563225434),\n",
      " (18, 0.06951682790986437),\n",
      " (19, 0.6013990840134688),\n",
      " (20, 0.12570547642032107),\n",
      " (21, 0.1484860647727601),\n",
      " (22, 0.13629457837964543),\n",
      " (23, 0.13835259755623772),\n",
      " (24, 0.0958091666977137)]\n"
     ]
    }
   ],
   "source": [
    "#Create tf-idf model object using models.TfidfModel on ‘bow_corpus’ and save it to ‘tfidf’, \n",
    "# then apply transformation to the entire corpus and call it ‘corpus_tfidf’.\n",
    "# Finally we preview TF-IDF scores for our first document.\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running LDA using Bag of Words\n",
    "# Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=20, id2word=dictionary, passes=2, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.026*\"apart\" + 0.022*\"kitchen\" + 0.017*\"towel\" + 0.015*\"need\" + 0.014*\"provid\" + 0.010*\"clean\" + 0.009*\"comfort\" + 0.008*\"bedroom\" + 0.008*\"coffe\" + 0.007*\"cook\"\n",
      "Topic: 1 \n",
      "Words: 0.046*\"park\" + 0.045*\"central\" + 0.038*\"apart\" + 0.036*\"locat\" + 0.036*\"walk\" + 0.034*\"squar\" + 0.031*\"time\" + 0.024*\"subway\" + 0.021*\"close\" + 0.020*\"block\"\n",
      "Topic: 2 \n",
      "Words: 0.040*\"space\" + 0.027*\"room\" + 0.019*\"comfort\" + 0.016*\"love\" + 0.014*\"bedroom\" + 0.012*\"bathroom\" + 0.012*\"apart\" + 0.012*\"privat\" + 0.012*\"host\" + 0.011*\"live\"\n",
      "Topic: 3 \n",
      "Words: 0.042*\"apart\" + 0.023*\"nois\" + 0.020*\"locat\" + 0.019*\"night\" + 0.018*\"sleep\" + 0.016*\"street\" + 0.013*\"clean\" + 0.012*\"place\" + 0.011*\"noisi\" + 0.010*\"comfort\"\n",
      "Topic: 4 \n",
      "Words: 0.040*\"apart\" + 0.038*\"locat\" + 0.033*\"perfect\" + 0.029*\"host\" + 0.028*\"love\" + 0.025*\"nice\" + 0.025*\"thank\" + 0.024*\"help\" + 0.018*\"place\" + 0.017*\"question\"\n",
      "Topic: 5 \n",
      "Words: 0.067*\"locat\" + 0.061*\"apart\" + 0.043*\"host\" + 0.042*\"clean\" + 0.035*\"place\" + 0.033*\"recommend\" + 0.031*\"easi\" + 0.027*\"communic\" + 0.022*\"definit\" + 0.020*\"comfort\"\n",
      "Topic: 6 \n",
      "Words: 0.047*\"home\" + 0.033*\"place\" + 0.028*\"like\" + 0.026*\"host\" + 0.022*\"feel\" + 0.021*\"felt\" + 0.020*\"time\" + 0.018*\"thank\" + 0.017*\"welcom\" + 0.016*\"friend\"\n",
      "Topic: 7 \n",
      "Words: 0.027*\"room\" + 0.019*\"apart\" + 0.014*\"bathroom\" + 0.013*\"place\" + 0.013*\"good\" + 0.012*\"locat\" + 0.011*\"clean\" + 0.011*\"floor\" + 0.010*\"door\" + 0.010*\"night\"\n",
      "Topic: 8 \n",
      "Words: 0.059*\"hous\" + 0.048*\"flat\" + 0.046*\"good\" + 0.036*\"clean\" + 0.034*\"nice\" + 0.024*\"locat\" + 0.020*\"room\" + 0.013*\"bathroom\" + 0.012*\"host\" + 0.012*\"pictur\"\n",
      "Topic: 9 \n",
      "Words: 0.039*\"apart\" + 0.027*\"check\" + 0.019*\"flight\" + 0.018*\"place\" + 0.017*\"locat\" + 0.015*\"stair\" + 0.013*\"super\" + 0.013*\"exact\" + 0.011*\"help\" + 0.011*\"time\"\n",
      "Topic: 10 \n",
      "Words: 0.069*\"arriv\" + 0.030*\"apart\" + 0.020*\"key\" + 0.017*\"host\" + 0.016*\"give\" + 0.014*\"late\" + 0.014*\"help\" + 0.013*\"leav\" + 0.012*\"day\" + 0.012*\"time\"\n",
      "Topic: 11 \n",
      "Words: 0.066*\"nice\" + 0.038*\"room\" + 0.034*\"park\" + 0.028*\"subway\" + 0.026*\"central\" + 0.025*\"close\" + 0.024*\"place\" + 0.018*\"apart\" + 0.017*\"help\" + 0.016*\"good\"\n",
      "Topic: 12 \n",
      "Words: 0.067*\"nice\" + 0.037*\"room\" + 0.037*\"appart\" + 0.034*\"good\" + 0.029*\"clean\" + 0.027*\"host\" + 0.025*\"locat\" + 0.022*\"friend\" + 0.022*\"place\" + 0.021*\"help\"\n",
      "Topic: 13 \n",
      "Words: 0.023*\"airbnb\" + 0.021*\"east\" + 0.021*\"villag\" + 0.021*\"place\" + 0.018*\"experi\" + 0.014*\"apart\" + 0.013*\"best\" + 0.011*\"host\" + 0.010*\"hotel\" + 0.010*\"like\"\n",
      "Topic: 14 \n",
      "Words: 0.110*\"place\" + 0.037*\"recommend\" + 0.027*\"host\" + 0.024*\"citi\" + 0.023*\"locat\" + 0.021*\"clean\" + 0.020*\"look\" + 0.020*\"time\" + 0.020*\"perfect\" + 0.018*\"comfort\"\n",
      "Topic: 15 \n",
      "Words: 0.119*\"check\" + 0.038*\"flexibl\" + 0.037*\"time\" + 0.025*\"apart\" + 0.021*\"accommod\" + 0.020*\"earli\" + 0.020*\"need\" + 0.016*\"help\" + 0.014*\"locat\" + 0.013*\"allow\"\n",
      "Topic: 16 \n",
      "Words: 0.031*\"place\" + 0.018*\"subway\" + 0.018*\"apart\" + 0.017*\"right\" + 0.017*\"comfort\" + 0.016*\"locat\" + 0.016*\"street\" + 0.016*\"close\" + 0.015*\"quiet\" + 0.014*\"neighborhood\"\n",
      "Topic: 17 \n",
      "Words: 0.042*\"place\" + 0.037*\"subway\" + 0.034*\"station\" + 0.021*\"walk\" + 0.020*\"apart\" + 0.020*\"minut\" + 0.019*\"close\" + 0.019*\"clean\" + 0.018*\"time\" + 0.017*\"away\"\n",
      "Topic: 18 \n",
      "Words: 0.028*\"walk\" + 0.021*\"place\" + 0.017*\"view\" + 0.014*\"apart\" + 0.014*\"room\" + 0.014*\"minut\" + 0.013*\"locat\" + 0.012*\"train\" + 0.012*\"clean\" + 0.011*\"build\"\n",
      "Topic: 19 \n",
      "Words: 0.054*\"restaur\" + 0.043*\"apart\" + 0.030*\"bar\" + 0.029*\"locat\" + 0.027*\"shop\" + 0.022*\"walk\" + 0.021*\"place\" + 0.020*\"subway\" + 0.019*\"close\" + 0.017*\"area\"\n"
     ]
    }
   ],
   "source": [
    "# For each topic, we will explore the words occuring in that topic and its relative weight.\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.894444465637207\t \n",
      "Topic: 0.033*\"place\" + 0.030*\"nice\" + 0.029*\"host\" + 0.028*\"locat\" + 0.022*\"good\" + 0.021*\"clean\" + 0.019*\"perfect\" + 0.019*\"recommend\" + 0.016*\"apart\" + 0.016*\"thank\"\n"
     ]
    }
   ],
   "source": [
    "# Running LDA using TF-IDF\n",
    "\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=20, id2word=dictionary, passes=2, workers=5)\n",
    "\n",
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.013*\"cute\" + 0.008*\"nice\" + 0.008*\"place\" + 0.007*\"apart\" + 0.007*\"friend\" + 0.007*\"room\" + 0.006*\"cat\" + 0.006*\"host\" + 0.006*\"clean\" + 0.006*\"help\"\n",
      "Topic: 1 \n",
      "Words: 0.019*\"villag\" + 0.016*\"east\" + 0.009*\"apart\" + 0.009*\"west\" + 0.009*\"soho\" + 0.009*\"place\" + 0.008*\"restaur\" + 0.008*\"heart\" + 0.008*\"locat\" + 0.007*\"walk\"\n",
      "Topic: 2 \n",
      "Words: 0.006*\"place\" + 0.006*\"apart\" + 0.006*\"hide\" + 0.005*\"free\" + 0.005*\"time\" + 0.005*\"easi\" + 0.004*\"clean\" + 0.004*\"sensit\" + 0.004*\"nice\" + 0.004*\"room\"\n",
      "Topic: 3 \n",
      "Words: 0.007*\"room\" + 0.006*\"apart\" + 0.005*\"place\" + 0.005*\"floor\" + 0.005*\"good\" + 0.005*\"night\" + 0.005*\"bathroom\" + 0.005*\"nice\" + 0.005*\"time\" + 0.004*\"clean\"\n",
      "Topic: 4 \n",
      "Words: 0.015*\"central\" + 0.015*\"park\" + 0.013*\"walk\" + 0.012*\"close\" + 0.012*\"subway\" + 0.011*\"restaur\" + 0.010*\"place\" + 0.010*\"squar\" + 0.010*\"apart\" + 0.009*\"locat\"\n",
      "Topic: 5 \n",
      "Words: 0.007*\"room\" + 0.006*\"apart\" + 0.006*\"good\" + 0.006*\"night\" + 0.006*\"nois\" + 0.005*\"sleep\" + 0.005*\"bedroom\" + 0.005*\"bathroom\" + 0.005*\"kitchen\" + 0.005*\"place\"\n",
      "Topic: 6 \n",
      "Words: 0.009*\"state\" + 0.009*\"empir\" + 0.006*\"place\" + 0.006*\"build\" + 0.006*\"time\" + 0.006*\"apart\" + 0.005*\"room\" + 0.005*\"walk\" + 0.005*\"nice\" + 0.004*\"host\"\n",
      "Topic: 7 \n",
      "Words: 0.007*\"place\" + 0.006*\"apart\" + 0.006*\"citi\" + 0.005*\"love\" + 0.005*\"nice\" + 0.005*\"home\" + 0.005*\"host\" + 0.005*\"perfect\" + 0.005*\"bustl\" + 0.005*\"time\"\n",
      "Topic: 8 \n",
      "Words: 0.047*\"reserv\" + 0.046*\"post\" + 0.046*\"cancel\" + 0.039*\"autom\" + 0.030*\"day\" + 0.023*\"arriv\" + 0.015*\"jam\" + 0.009*\"charli\" + 0.008*\"frill\" + 0.008*\"notch\"\n",
      "Topic: 9 \n",
      "Words: 0.033*\"place\" + 0.030*\"nice\" + 0.029*\"host\" + 0.028*\"locat\" + 0.022*\"good\" + 0.021*\"clean\" + 0.019*\"perfect\" + 0.019*\"recommend\" + 0.016*\"apart\" + 0.016*\"thank\"\n",
      "Topic: 10 \n",
      "Words: 0.007*\"place\" + 0.007*\"michael\" + 0.006*\"apart\" + 0.006*\"help\" + 0.006*\"host\" + 0.006*\"nice\" + 0.006*\"time\" + 0.005*\"recommend\" + 0.005*\"reachabl\" + 0.005*\"thank\"\n",
      "Topic: 11 \n",
      "Words: 0.021*\"transport\" + 0.021*\"public\" + 0.011*\"place\" + 0.011*\"hospit\" + 0.011*\"close\" + 0.011*\"cozi\" + 0.009*\"host\" + 0.009*\"clean\" + 0.009*\"nice\" + 0.008*\"welcom\"\n",
      "Topic: 12 \n",
      "Words: 0.008*\"place\" + 0.008*\"star\" + 0.008*\"host\" + 0.007*\"apart\" + 0.007*\"nice\" + 0.006*\"best\" + 0.006*\"clean\" + 0.006*\"locat\" + 0.006*\"perfect\" + 0.006*\"help\"\n",
      "Topic: 13 \n",
      "Words: 0.019*\"check\" + 0.013*\"exact\" + 0.012*\"describ\" + 0.011*\"accommod\" + 0.011*\"easi\" + 0.011*\"place\" + 0.011*\"apart\" + 0.011*\"communic\" + 0.010*\"host\" + 0.009*\"locat\"\n",
      "Topic: 14 \n",
      "Words: 0.020*\"price\" + 0.010*\"place\" + 0.010*\"good\" + 0.009*\"nice\" + 0.008*\"room\" + 0.007*\"locat\" + 0.007*\"host\" + 0.007*\"clean\" + 0.007*\"reason\" + 0.006*\"afford\"\n",
      "Topic: 15 \n",
      "Words: 0.022*\"view\" + 0.010*\"amaz\" + 0.009*\"rooftop\" + 0.009*\"beauti\" + 0.009*\"apart\" + 0.008*\"place\" + 0.007*\"love\" + 0.007*\"nice\" + 0.007*\"perfect\" + 0.007*\"host\"\n",
      "Topic: 16 \n",
      "Words: 0.009*\"alex\" + 0.008*\"place\" + 0.007*\"apart\" + 0.006*\"nice\" + 0.006*\"good\" + 0.006*\"host\" + 0.005*\"locat\" + 0.005*\"recommend\" + 0.005*\"restaur\" + 0.005*\"help\"\n",
      "Topic: 17 \n",
      "Words: 0.017*\"valu\" + 0.008*\"money\" + 0.007*\"place\" + 0.007*\"good\" + 0.007*\"apart\" + 0.006*\"room\" + 0.006*\"comfort\" + 0.006*\"locat\" + 0.006*\"nice\" + 0.005*\"clean\"\n",
      "Topic: 18 \n",
      "Words: 0.009*\"place\" + 0.007*\"apart\" + 0.006*\"locat\" + 0.006*\"perfect\" + 0.006*\"host\" + 0.006*\"nice\" + 0.006*\"easi\" + 0.006*\"crash\" + 0.006*\"recommend\" + 0.006*\"clean\"\n",
      "Topic: 19 \n",
      "Words: 0.008*\"place\" + 0.008*\"accomod\" + 0.007*\"host\" + 0.007*\"apart\" + 0.007*\"recommend\" + 0.006*\"locat\" + 0.006*\"clean\" + 0.006*\"perfect\" + 0.006*\"help\" + 0.006*\"nice\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.894444465637207\t \n",
      "Topic: 0.033*\"place\" + 0.030*\"nice\" + 0.029*\"host\" + 0.028*\"locat\" + 0.022*\"good\" + 0.021*\"clean\" + 0.019*\"perfect\" + 0.019*\"recommend\" + 0.016*\"apart\" + 0.016*\"thank\"\n"
     ]
    }
   ],
   "source": [
    "# Performance evaluation by classifying sample document using LDA TF-IDF model.\n",
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Airbnb 3.7",
   "language": "python",
   "name": "airbnb_p3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
